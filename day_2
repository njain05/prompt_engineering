# 📘 Day 02

## ✅ Topic Covered
Deep Dive into Generative AI, LLMs, and Key Terminologies in Prompt Engineering

## 🧠 Summary
Today’s session focused on understanding the working of **Generative AI** and how it differs from traditional AI. We explored various generative tools and models, 
including both text-based and image-based systems. A detailed introduction to **Large Language Models (LLMs)** was provided, 
along with essential terms used frequently in this field.

We also understood the **input-process-output cycle** using prompts and how models process language using parameters, tokens, and inference mechanisms.
The use of analogies made technical concepts much easier to digest — like comparing tokens to ingredients and parameters to recipes.

## 🧪 Examples & Tools Mentioned

| Category           | Examples/Tools                              | Use Case                            |
|-------------------|----------------------------------------------|-------------------------------------|
| Text Generation    | ChatGPT, Gemini, Grok, DeepSeek              | Text-based outputs                  |
| Image Generation   | DALL·E, Diffusion Models                     | Creating images from text prompts   |
| Code Assistants    | GitHub Copilot, CodeX                        | Code generation, debugging          |
| Speech Tools       | Whisper, Google Speech                       | Voice-to-text and vice versa        |

## 🔍 New Concepts Learned
- Generative AI vs Traditional AI
- Input → Processing → Output pipeline
- Prompting: crafting questions/inputs
- LLM (Large Language Model) structure
- Tokens, Parameters, Inference, Fine-tuning
- Analogy: Tokens = ingredients, Parameters = recipe, Inference = final dish

## 💻 Activity
- Compared traditional vs generative AI approaches
- Identified tools based on input-output type
- Studied LLM internals and how they use training data
- Wrote and tested sample prompts

## 🤔 Challenges Faced
Understanding how models “predict” without truly understanding like humans do was tricky at first. The examples helped, but it still feels complex.

## 🎯 Key Takeaway
Generative AI is like a predictive engine — it doesn’t "know" but it’s trained to guess very well based on patterns.

## 📈 Understanding Today: 8.7/10
