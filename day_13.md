# ğŸ“˜ Day 13

## âœ… Topics Covered
- Introduction to Functions in Prompt Engineering
- Use of `functions` tool in OpenAI and Google models
- Schema definition (parameter inputs)
- Structured output handling
- When and why to use function calling

## ğŸ§  Summary
Today was all about **structured prompting using functions**. We learned how to define a function schema that tells the LLM exactly what to extract and return. This allows for better **control** and **reliability** in the output â€” especially in real-world applications like chatbots, automation tools, or decision systems.

We explored both OpenAIâ€™s and Googleâ€™s function calling features, and discussed how functions can help AI move from free-form text to predictable, structured JSON-like outputs.

This makes AI more usable in software pipelines!

## ğŸ” New Concepts Learned
- Function schemas: name, description, parameters
- JSON schema basics for prompt functions
- Role of functions in safe and reliable AI use
- Integrating LLM output into workflows via function calling

## ğŸ’» Activity

| Task                          | Description                                                 |
|-------------------------------|-------------------------------------------------------------|
| Schema Design                 | Designed sample function schema for a movie recommendation |
| Function Call Demo            | Passed the schema to ChatGPT and tested multiple prompts    |
| Comparison with normal prompts| Observed how structured output avoids ambiguity             |

## ğŸ¤” Challenges Faced
- Understanding JSON structure validation took some time
- Needed multiple tries to get parameter names/descriptions right

## ğŸ¯ Key Takeaway
**Functions turn LLMs into APIs â€” precise, predictable, and programmable.**

## ğŸ“ˆ Understanding Today: 9/10
