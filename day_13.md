# 📘 Day 13

## ✅ Topics Covered
- Introduction to Functions in Prompt Engineering
- Use of `functions` tool in OpenAI and Google models
- Schema definition (parameter inputs)
- Structured output handling
- When and why to use function calling

## 🧠 Summary
Today was all about **structured prompting using functions**. We learned how to define a function schema that tells the LLM exactly what to extract and return. This allows for better **control** and **reliability** in the output — especially in real-world applications like chatbots, automation tools, or decision systems.

We explored both OpenAI’s and Google’s function calling features, and discussed how functions can help AI move from free-form text to predictable, structured JSON-like outputs.

This makes AI more usable in software pipelines!

## 🔍 New Concepts Learned
- Function schemas: name, description, parameters
- JSON schema basics for prompt functions
- Role of functions in safe and reliable AI use
- Integrating LLM output into workflows via function calling

## 💻 Activity

| Task                          | Description                                                 |
|-------------------------------|-------------------------------------------------------------|
| Schema Design                 | Designed sample function schema for a movie recommendation |
| Function Call Demo            | Passed the schema to ChatGPT and tested multiple prompts    |
| Comparison with normal prompts| Observed how structured output avoids ambiguity             |

## 🤔 Challenges Faced
- Understanding JSON structure validation took some time
- Needed multiple tries to get parameter names/descriptions right

## 🎯 Key Takeaway
**Functions turn LLMs into APIs — precise, predictable, and programmable.**

## 📈 Understanding Today: 9/10
