# ğŸ“˜ Day 14

## âœ… Topics Covered
- Custom Functions for AI Models
- Agents in Prompt Engineering
- Agentic AI vs Traditional AI
- Tool Use and Multi-step Reasoning
- Introduction to ReAct and Plan-and-Execute frameworks

## ğŸ§  Summary
Today's session was one of the most exciting so far â€” we learned how to give AI models **tools** (like search, calculator, or custom APIs) using **agents**. Unlike static prompting, agent-based prompting allows the LLM to plan, decide, and execute actions using tools in multiple steps.

We also covered how **Custom Functions** can be designed to handle domain-specific tasks, such as math solvers, database query handlers, or image analyzers.

The idea of **Agentic AI** really stood out â€” where models donâ€™t just answer, they **act** intelligently across tasks.

## ğŸ” New Concepts Learned
- Agentic prompting and reasoning
- ReAct (Reasoning + Acting) framework
- Tool calling vs Function calling
- Role of memory in multi-step agents
- When to build custom agents

## ğŸ’» Activity

| Task                            | Description                                                   |
|----------------------------------|---------------------------------------------------------------|
| Custom Tool Design               | Created a custom currency converter function                  |
| ReAct Framework Exploration      | Used a prompt chain to reason and call search tool            |
| Multi-tool Use Case              | Designed a flow combining search + calculator + summarizer    |

## ğŸ¤” Challenges Faced
- Managing the logic flow of agent decisions
- Tools failing when not configured properly
- Slightly overwhelming due to multi-step structure

## ğŸ¯ Key Takeaway
**Agents transform LLMs from responders to problem solvers.**  
Custom functions and tool use are what make AI models act like true assistants.

## ğŸ“ˆ Understanding Today: 9.2/10
