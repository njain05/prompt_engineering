# 📘 Day 14

## ✅ Topics Covered
- Custom Functions for AI Models
- Agents in Prompt Engineering
- Agentic AI vs Traditional AI
- Tool Use and Multi-step Reasoning
- Introduction to ReAct and Plan-and-Execute frameworks

## 🧠 Summary
Today's session was one of the most exciting so far — we learned how to give AI models **tools** (like search, calculator, or custom APIs) using **agents**. Unlike static prompting, agent-based prompting allows the LLM to plan, decide, and execute actions using tools in multiple steps.

We also covered how **Custom Functions** can be designed to handle domain-specific tasks, such as math solvers, database query handlers, or image analyzers.

The idea of **Agentic AI** really stood out — where models don’t just answer, they **act** intelligently across tasks.

## 🔍 New Concepts Learned
- Agentic prompting and reasoning
- ReAct (Reasoning + Acting) framework
- Tool calling vs Function calling
- Role of memory in multi-step agents
- When to build custom agents

## 💻 Activity

| Task                            | Description                                                   |
|----------------------------------|---------------------------------------------------------------|
| Custom Tool Design               | Created a custom currency converter function                  |
| ReAct Framework Exploration      | Used a prompt chain to reason and call search tool            |
| Multi-tool Use Case              | Designed a flow combining search + calculator + summarizer    |

## 🤔 Challenges Faced
- Managing the logic flow of agent decisions
- Tools failing when not configured properly
- Slightly overwhelming due to multi-step structure

## 🎯 Key Takeaway
**Agents transform LLMs from responders to problem solvers.**  
Custom functions and tool use are what make AI models act like true assistants.

## 📈 Understanding Today: 9.2/10
